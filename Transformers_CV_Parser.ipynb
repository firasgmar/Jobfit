{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i7nBHulz-L3i",
        "outputId": "099a8f1a-f95d-4f32-856b-b9d64754b63f"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install PyMuPDF\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLZAad7iAJoy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XIROyECG-QP9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\161\\PythonRepository\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import fitz\n",
        "import re\n",
        "class TR_parser:\n",
        "  def __init__(self):\n",
        "    # Specify the LLM model we'll be using\n",
        "    model_name = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "    #model_name =\"gpt2\"\n",
        "    # Configure for GPU usage\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    # Load the tokenizer for the chosen model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # Create a pipeline object for easy text generation with the LLM\n",
        "    self.pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    # Parameters to control LLM's response generation\n",
        "\n",
        "  def query(self,messages):\n",
        "    generation_args = {\n",
        "        \"max_new_tokens\": 256,     # Maximum length of the response\n",
        "        \"return_full_text\": False,      # Only return the generated text\n",
        "    }\n",
        "    \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
        "\n",
        "    Args:\n",
        "      messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
        "\n",
        "    Returns:\n",
        "      str: The answer from the AI assistant.\n",
        "    \"\"\"\n",
        "\n",
        "    output = self.pipe(messages, **generation_args)\n",
        "    return output[0]['generated_text']\n",
        "  def get_name(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Return the name of the person in CV data in this format  Name:  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_phone_number(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Return the phone number of the person in CV data in this format  phone number:  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_mail(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Return the mail of the person in CV data in this format  phone mail:  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_about(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"generat a Summary profil  for the person in CV data,in this format  Summary:  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_hobbies(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"get hobbies of the person in CV data,in this list format  Hobbies:[]  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_education(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"get education degrees of the person in CV data,in this list format  Education:[]  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_experience(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"get experiences  of the person in CV data,in this list format  experiences:[]  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def get_languages(self,text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"get languages  of the person in CV data,in this format  languages:[]  \"},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    result = self.query(messages)\n",
        "    return result\n",
        "  def extract_text_from_pdf(self,pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "  def clean_extracted_text(self,text):\n",
        "      # Supprimer les espaces multiples\n",
        "      text = re.sub(r'\\s+', ' ', text)\n",
        "      # Supprimer les nouvelles lignes multiples\n",
        "      text = re.sub(r'\\n+', '\\n', text)\n",
        "      return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z1wf-cy7-WYr"
      },
      "outputs": [],
      "source": [
        "class personCV:\n",
        "  def __init__(self,parser,cvtext,cvpath):\n",
        "    #if type(parser)==TR_parser:\n",
        "      self.cv_path=cvpath\n",
        "      name=parser.get_name(cvtext)\n",
        "      self.name=name.split(sep=\":\")[1]\n",
        "      phone_number=parser.get_phone_number(cvtext)\n",
        "      self.phonenumber=phone_number.split(sep=\":\")[1]\n",
        "      mail=parser.get_mail(cvtext)\n",
        "      self.mail=mail.split(sep=\":\")[1]\n",
        "      Summary=parser.get_about(cvtext)\n",
        "      self.summary=Summary\n",
        "      hobbies=parser.get_hobbies(cvtext)\n",
        "      self.hobbies=hobbies\n",
        "      education=parser.get_education(cvtext)\n",
        "      self.education=education\n",
        "      experience=parser.get_experience(cvtext)\n",
        "      self.experience=experience\n",
        "      languages=parser.get_languages(cvtext)\n",
        "      self.languages=languages\n",
        "\n",
        "    #else:\n",
        "    #  self.name=None\n",
        "    #  self.phonenumber=None\n",
        "\n",
        "\n",
        "\n",
        "  def get_name(self):\n",
        "    return self.name\n",
        "  def get_phone_number(self):\n",
        "    return self.phonenumber\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_BOCex8-Wy9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rPjrTJUMCO8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\161\\PythonRepository\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\161\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-0.5B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "trp=TR_parser()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeNkw2-K_rnB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dossier_pdf='/content/drive/MyDrive/cv'\n",
        "for filename in os.listdir(dossier_pdf):\n",
        "    if filename.endswith('.pdf'):\n",
        "        filename='Aymen__Hmid_CV.pdf'\n",
        "        resume_path = os.path.join(dossier_pdf, filename)\n",
        "        text = trp.extract_text_from_pdf(resume_path)\n",
        "        text = trp.clean_extracted_text(text)\n",
        "        person=personCV(trp,text,resume_path)\n",
        "        print(person.get_name())\n",
        "        print(person.get_phone_number())\n",
        "        print(person.get_mail())\n",
        "        print\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh1BXeNqLjPD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
